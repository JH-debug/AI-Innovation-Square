{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### < Topic >\n",
    "\n",
    "1. review\n",
    "    \n",
    "    1.1 전처리: BPE까지\n",
    "    \n",
    "    1.2 N-gram 언어 모델\n",
    "\n",
    "\n",
    "2. topic\n",
    "\n",
    "    2.1 단어 표현 (BoW, DTM, TF-IDF)\n",
    "    \n",
    "    2.2 문서 유사도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 로드\n",
    "\n",
    "movie_comments = []\n",
    "\n",
    "with open('comment_1917.txt', 'r', encoding = 'utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        movie_comments.append(line.rstrip('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['충무로: 이거 어케하는거냐?', '', '촬영감독의 영혼까지 갈아넣은 마스터피스', '', '오스카 작품상 탔어도 할말 없었을것 같다.', '', '주인공을 카메라가 계속 따라가는데.. 세트장이 엄청 넓은거에 놀랐습니다. 직접 1차대전에 참전하는 느낌.. 이때당시 군인들 20년뒤 히틀러라는 극악의 악마로 자식들 다 전장에 몰리고 더 최악의 고통을 받을껀데 참.....', '', '닥터스트레인지의 판단력이 좋았다.', '', '아카데미 작품상이야 작품전체를 보는거니 기생충이 받을수도 있다고 보는데 감독상은 1917 줬어도 할말 없음. 감독의 참신성이 빛을 발함. 결론적으로 아카데미 작품상과 감독상을 1917이 받았어도 아무 할말 없는 것이...', '', '솔직히 연출력만으로 최고의 영화다. 마치 우리가 투명인간이 되서 그들을 지켜보는 듯했다. 마지막장면은 영화 내내 쉴시간이 없었던것에 대한 피로감을 풀어줘서 기승전결도 완벽.', '', '스포일러가 포함된 감상평입니다. 감상평 보기', '', '진짜 원테이크 장면 너무 긴거 아님?? 촬영하기 진짜 힘들었을 듯...', '', '솔직히 나는 기생충보다 이영화가 더 재미있었다.', '', '막판에 횡으로 수많은 병사가 신호와 함께 우르르 튀어나올때 주인공 혼자 종으로 막 달리는 장면 와 진짜ㅋㅋㅋㅋ대박 무조건 아이맥스로 보세요!', '', '원테이크 촬영신은 볼때마다 대단하다 후보에 오를만 했음', '', '스포일러가 포함된 감상평입니다. 감상평 보기', '']\n"
     ]
    }
   ],
   "source": [
    "print(movie_comments[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['충무로 이거 어케하는거냐', '', '촬영감독의 영혼까지 갈아넣은 마스터피스', '', '오스카 작품상 탔어도 할말 없었을것 같다', '', '주인공을 카메라가 계속 따라가는데 세트장이 엄청 넓은거에 놀랐습니다 직접 1차대전에 참전하는 느낌 이때당시 군인들 20년뒤 히틀러라는 극악의 악마로 자식들 다 전장에 몰리고 더 최악의 고통을 받을껀데 참', '', '닥터스트레인지의 판단력이 좋았다', '', '아카데미 작품상이야 작품전체를 보는거니 기생충이 받을수도 있다고 보는데 감독상은 1917 줬어도 할말 없음 감독의 참신성이 빛을 발함 결론적으로 아카데미 작품상과 감독상을 1917이 받았어도 아무 할말 없는 것이', '', '솔직히 연출력만으로 최고의 영화다 마치 우리가 투명인간이 되서 그들을 지켜보는 듯했다 마지막장면은 영화 내내 쉴시간이 없었던것에 대한 피로감을 풀어줘서 기승전결도 완벽', '', '스포일러가 포함된 감상평입니다 감상평 보기', '', '진짜 원테이크 장면 너무 긴거 아님 촬영하기 진짜 힘들었을 듯', '', '솔직히 나는 기생충보다 이영화가 더 재미있었다', '', '막판에 횡으로 수많은 병사가 신호와 함께 우르르 튀어나올때 주인공 혼자 종으로 막 달리는 장면 와 진짜ㅋㅋㅋㅋ대박 무조건 아이맥스로 보세요', '', '원테이크 촬영신은 볼때마다 대단하다 후보에 오를만 했음', '', '스포일러가 포함된 감상평입니다 감상평 보기', '']\n"
     ]
    }
   ],
   "source": [
    "# cleaning: 특수문자 제거\n",
    "\n",
    "import re\n",
    "\n",
    "r = '[-=+,#/\\?:^$.@*\\\"~&%.!\\'|\\(\\)\\[\\]\\<\\>`\\']'\n",
    "\n",
    "movie_new_comments = []\n",
    "for comment in movie_comments:\n",
    "    movie_new_comments.append(re.sub(r, '', comment))\n",
    "\n",
    "print(movie_new_comments[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불용어 처리\n",
    "\n",
    "stop_words = []\n",
    "\n",
    "with open('stopwords.txt', 'r', encoding = 'utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        stop_words.append(line.rstrip('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['충무로', '거', '어케', '하는거냐', '촬영감독', '영혼', '갈아', '넣은', '마스터피스', '오스카', '작품', '상', '탔어도', '할말', '없었을것', '주인공', '카메라', '계속', '따라가는데', '세트', '장이', '엄청', '넓은거에', '놀랐습니다', '직접', '1', '차', '대전', '참전', '하는', '느낌', '당시', '군', '인들', '20년', '뒤', '히틀러', '라는', '극악', '악마', '자식', '다', '전장', '몰리', '고', '더', '최악', '고통', '받을껀데', '닥터스', '트레인', '지', '판단력', '좋았다', '아카데미', '작품', '상', '이야', '작품', '전체', '보는거니', '기생충', '받을수도', '있다고', '보는데', '감독', '상', '은', '1917', '줬어도', '할말', '없음', '감독', '참신', '성', '빛', '발함', '결론', '적', '아카데미', '작품', '상과', '감독', '상', '1917', '받았어도', '아무', '할말', '없는', '솔직히', '연출', '력', '만으로', '최고', '영화', '다', '투명인간', '되서', '지켜보는', '듯']\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for comment in movie_new_comments:\n",
    "    for word in okt.morphs(comment):\n",
    "        if word not in stop_words:\n",
    "            results.append(word)\n",
    "\n",
    "print(results[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 단어 분리 (Byte Pair Encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - 단어 집합 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts = tokenizer.word_counts.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특수기호 '/w'를 넣은 뒤, 한 글자 단위로 모두 띄어 초기화\n",
    "\n",
    "vocab = {}\n",
    "\n",
    "for key, item in word_counts:\n",
    "    key = ' '.join(key)\n",
    "    key += ' </w>'      # 단어 맨 끝에 붙이는 특수 문자\n",
    "    vocab[key] = item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    word_counts -> [ ( '홍길동', 5 ), ( '김길동', 3 ) ... ]\n",
    "    'l o w </w>' : 5 -> 파이썬의 dictionary 이용해서 BPE 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'충 무 로 </w>': 1, '거 </w>': 1, '어 케 </w>': 1, '하 는 거 냐 </w>': 1, '촬 영 감 독 </w>': 1, '영 혼 </w>': 1, '갈 아 </w>': 1, '넣 은 </w>': 1, '마 스 터 피 스 </w>': 1, '오 스 카 </w>': 1, '작 품 </w>': 4, '상 </w>': 4, '탔 어 도 </w>': 1, '할 말 </w>': 3, '없 었 을 것 </w>': 1, '주 인 공 </w>': 2, '카 메 라 </w>': 1, '계 속 </w>': 1, '따 라 가 는 데 </w>': 1, '세 트 </w>': 1, '장 이 </w>': 1, '엄 청 </w>': 1, '넓 은 거 에 </w>': 1, '놀 랐 습 니 다 </w>': 1, '직 접 </w>': 1, '1 </w>': 1, '차 </w>': 1, '대 전 </w>': 1, '참 전 </w>': 1, '하 는 </w>': 1, '느 낌 </w>': 1, '당 시 </w>': 1, '군 </w>': 1, '인 들 </w>': 1, '2 0 년 </w>': 1, '뒤 </w>': 1, '히 틀 러 </w>': 1, '라 는 </w>': 1, '극 악 </w>': 1, '악 마 </w>': 1, '자 식 </w>': 1, '다 </w>': 2, '전 장 </w>': 1, '몰 리 </w>': 1, '고 </w>': 1, '더 </w>': 2, '최 악 </w>': 1, '고 통 </w>': 1, '받 을 껀 데 </w>': 1, '닥 터 스 </w>': 1, '트 레 인 </w>': 1, '지 </w>': 1, '판 단 력 </w>': 1, '좋 았 다 </w>': 1, '아 카 데 미 </w>': 2, '이 야 </w>': 1, '전 체 </w>': 1, '보 는 거 니 </w>': 1, '기 생 충 </w>': 2, '받 을 수 도 </w>': 1, '있 다 고 </w>': 1, '보 는 데 </w>': 1, '감 독 </w>': 3, '은 </w>': 2, '1 9 1 7 </w>': 2, '줬 어 도 </w>': 1, '없 음 </w>': 1, '참 신 </w>': 1, '성 </w>': 1, '빛 </w>': 1, '발 함 </w>': 1, '결 론 </w>': 1, '적 </w>': 1, '상 과 </w>': 1, '받 았 어 도 </w>': 1, '아 무 </w>': 1, '없 는 </w>': 1, '솔 직 히 </w>': 2, '연 출 </w>': 1, '력 </w>': 1, '만 으 로 </w>': 1, '최 고 </w>': 1, '영 화 </w>': 2, '투 명 인 간 </w>': 1, '되 서 </w>': 1, '지 켜 보 는 </w>': 1, '듯 </w>': 2, '했 다 </w>': 1, '마 지 막 </w>': 1, '장 면 </w>': 3, '내 내 </w>': 1, '쉴 </w>': 1, '없 었 던 것 에 </w>': 1, '대 한 </w>': 1, '피 로 </w>': 1, '감 </w>': 1, '풀 어 줘 서 </w>': 1, '기 승 </w>': 1, '전 결 </w>': 1, '도 </w>': 1, '완 벽 </w>': 1, '스 포 일 러 </w>': 2, '포 함 </w>': 2, '된 </w>': 2, '감 상 </w>': 4, '평 </w>': 4, '입 니 다 </w>': 2, '보 기 </w>': 2, '진 짜 </w>': 3, '원 </w>': 2, '테 이 크 </w>': 2, '너 무 </w>': 1, '긴 거 </w>': 1, '아 님 </w>': 1, '촬 영 </w>': 2, '하 기 </w>': 1, '힘 들 었 을 </w>': 1, '는 </w>': 1, '보 다 </w>': 1, '이 영 화 </w>': 1, '재 미 있 었 다 </w>': 1, '막 판 </w>': 1, '횡 </w>': 1, '수 많 은 </w>': 1, '병 사 </w>': 1, '신 호 </w>': 1, '튀 어 나 올 </w>': 1, '종 </w>': 1, '막 </w>': 1, '달 리 는 </w>': 1, 'ㅋ ㅋ ㅋ ㅋ </w>': 1, '대 박 </w>': 1, '무 조 건 </w>': 1, '아 이 맥 스 </w>': 1, '보 세 요 </w>': 1, '신 은 </w>': 1, '볼 때 </w>': 1, '마 다 </w>': 1, '대 단 하 다 </w>': 1, '후 보 </w>': 1, '오 를 만 </w>': 1, '했 음 </w>': 1}\n"
     ]
    }
   ],
   "source": [
    "print(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - BPE(단어 분리) 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "# 글자별 빈도수 계산\n",
    "\n",
    "def get_stats(vocab):\n",
    "    pairs = collections.defaultdict(int)   # key 없이 사용할 수 있는 defaultdictict\n",
    "    for word, freq in vocab.items():    # dictionary: key: 단어수 - value: 빈도수\n",
    "        symbols = word.split()\n",
    "        for i in range(len(symbols)-1):\n",
    "            pairs[symbols[i],symbols[i+1]] += freq\n",
    "    return pairs\n",
    "\n",
    "# 글자 빈도수에 따른 유니그램 작성 (빈도수가 높은 순대로 합침)\n",
    "\n",
    "def merge_vocab(pair, v_in):\n",
    "    v_out = {}\n",
    "    bigram = re.escape(' '.join(pair))\n",
    "    p = re.compile(r'(?<!\\S)' + bigram + r'(?!\\S)')\n",
    "    for word in v_in:\n",
    "        w_out = p.sub(''.join(pair), word)\n",
    "        v_out[w_out] = v_in[word]\n",
    "    return v_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('평', '</w>')\n",
      "('로', '</w>')\n",
      "('촬', '영')\n",
      "('스', '</w>')\n",
      "('어', '도</w>')\n",
      "('할', '말')\n",
      "('할말', '</w>')\n",
      "('데', '</w>')\n",
      "('니', '다</w>')\n",
      "('러', '</w>')\n",
      "('고', '</w>')\n",
      "('함', '</w>')\n",
      "('영', '화')\n",
      "('영화', '</w>')\n",
      "('장', '면')\n",
      "('장면', '</w>')\n",
      "('기', '</w>')\n",
      "('진', '짜')\n",
      "('진짜', '</w>')\n",
      "('ㅋ', 'ㅋ')\n"
     ]
    }
   ],
   "source": [
    "# BPE 수행 함수\n",
    "\n",
    "num_merges = 20\n",
    "\n",
    "for i in range(num_merges):\n",
    "    pairs = get_stats(vocab)\n",
    "    best = max(pairs, key=pairs.get)\n",
    "    vocab = merge_vocab(best, vocab)\n",
    "    print(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "\n",
    "## [ Text Preprocessing ]\n",
    "\n",
    "    1. Tokenization\n",
    "    2. Cleaning\n",
    "    3. Normalization\n",
    "    \n",
    "    4. Lemmatization (표제어 추출)\n",
    "    5. Stemming (어간 추출)\n",
    "    \n",
    "    6. Stopword 처리\n",
    "\n",
    "    7. 단어 표현 (국소 단어 표현)\n",
    "        7.0 Integer encoding\n",
    "        7.1 One-hot encoding\n",
    "        7.2 BPE\n",
    "        \n",
    "    8. 데이터 분리\n",
    "\n",
    "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 언어 모델(Language Model) \n",
    "### : 통계를 이용한 LM, 인공신경망을 이용한 LM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - N-gram 언어 모델 (확률적 언어 모델)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import ngrams\n",
    "from nltk import ConditionalFreqDist\n",
    "from nltk.probability import ConditionalProbDist, MLEProbDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('SS', '충'),\n",
       " ('충', '무'),\n",
       " ('무', '로'),\n",
       " ('로', ' '),\n",
       " (' ', '이'),\n",
       " ('이', '거'),\n",
       " ('거', ' '),\n",
       " (' ', '어'),\n",
       " ('어', '케'),\n",
       " ('케', '하'),\n",
       " ('하', '는'),\n",
       " ('는', '거'),\n",
       " ('거', '냐'),\n",
       " ('냐', 'SE'),\n",
       " ('SS', 'SE'),\n",
       " ('SS', '촬'),\n",
       " ('촬', '영'),\n",
       " ('영', '감'),\n",
       " ('감', '독'),\n",
       " ('독', '의')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = []\n",
    "\n",
    "for tokens in movie_new_comments:\n",
    "    bigram = ngrams(tokens, 2, pad_left = True, pad_right = True, \n",
    "                   left_pad_symbol = 'SS', right_pad_symbol = 'SE')\n",
    "    sentences += [t for t in bigram]\n",
    "\n",
    "sentences[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ConditionalFreqDist 클래스를 이용한 단어 빈도수 계산\n",
    "\n",
    "cdf = ConditionalFreqDist(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('SE', 13),\n",
       " ('솔', 2),\n",
       " ('스', 2),\n",
       " ('충', 1),\n",
       " ('촬', 1),\n",
       " ('오', 1),\n",
       " ('주', 1),\n",
       " ('닥', 1),\n",
       " ('아', 1),\n",
       " ('진', 1)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdf[\"SS\"].most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('화', 3), ('감', 1), ('혼', 1), ('하', 1), ('신', 1)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdf[\"영\"].most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1630bb46eb8>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 시각화\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib import font_manager\n",
    "font_name = font_manager.FontProperties(fname=\"c:/Windows/Fonts/malgun.ttf\").get_name()\n",
    "plt.rc('font', family= font_name)\n",
    "\n",
    "plt.subplot(311)\n",
    "cdf[\"총\"].plot(5, title = '총 다음 단어 분포')\n",
    "plt.subplot(312)\n",
    "cdf[\"영\"].plot(5, title = '영 다음 단어 분포')\n",
    "plt.subplot(313)\n",
    "cdf[\"촬\"].plot(5, title = '촬 다음 단어 분포')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ConditionalProbDist: 조건부 확률값이나 샘플 확률에 대한 로그 확률\n",
    "\n",
    "cpd = ConditionalProbDist(cdf, MLEProbDist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('무', 1), ('이', 1), ('보', 1)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdf[\"충\"].most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpd[\"충\"].prob(\"무\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('화', 3), ('감', 1), ('혼', 1), ('하', 1), ('신', 1)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdf[\"영\"].most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42857142857142855"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpd[\"영\"].prob(\"화\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14285714285714285"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpd[\"영\"].prob(\"혼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - 무작위 문장 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['충무로/Noun', '이/Determiner', '거/Noun', '어케/Noun', '하는거냐/Verb']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 품사 태깅하는 tokenize 함수 생성\n",
    "\n",
    "def tokenize(doc):\n",
    "    tokens = ['/'.join(t) for t in okt.pos(doc)]\n",
    "    return tokens\n",
    "\n",
    "tokenize(movie_new_comments[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 210.24it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('SS', '충무로/Noun'),\n",
       " ('충무로/Noun', '이/Determiner'),\n",
       " ('이/Determiner', '거/Noun'),\n",
       " ('거/Noun', '어케/Noun'),\n",
       " ('어케/Noun', '하는거냐/Verb'),\n",
       " ('하는거냐/Verb', 'SE'),\n",
       " ('SS', 'SE'),\n",
       " ('SS', '촬영감독/Noun'),\n",
       " ('촬영감독/Noun', '의/Josa'),\n",
       " ('의/Josa', '영혼/Noun'),\n",
       " ('영혼/Noun', '까지/Josa'),\n",
       " ('까지/Josa', '갈아/Adverb'),\n",
       " ('갈아/Adverb', '넣은/Verb'),\n",
       " ('넣은/Verb', '마스터피스/Noun'),\n",
       " ('마스터피스/Noun', 'SE'),\n",
       " ('SS', 'SE'),\n",
       " ('SS', '오스카/Noun'),\n",
       " ('오스카/Noun', '작품/Noun'),\n",
       " ('작품/Noun', '상/Suffix'),\n",
       " ('상/Suffix', '탔어도/Verb'),\n",
       " ('탔어도/Verb', '할말/Verb'),\n",
       " ('할말/Verb', '없었을것/Adjective'),\n",
       " ('없었을것/Adjective', '같다/Adjective'),\n",
       " ('같다/Adjective', 'SE'),\n",
       " ('SS', 'SE'),\n",
       " ('SS', '주인공/Noun'),\n",
       " ('주인공/Noun', '을/Josa'),\n",
       " ('을/Josa', '카메라/Noun'),\n",
       " ('카메라/Noun', '가/Josa'),\n",
       " ('가/Josa', '계속/Noun')]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bigram 생성\n",
    "\n",
    "from tqdm import tqdm  # progress bar\n",
    "\n",
    "sentences = []\n",
    "for d in tqdm(movie_new_comments):\n",
    "    tokens = tokenize(d)\n",
    "    bigram = ngrams(tokens, 2, pad_left = True, pad_right = True,\n",
    "                  left_pad_symbol = 'SS', right_pad_symbol = 'SE')\n",
    "    sentences += [t for t in bigram]\n",
    "    \n",
    "sentences[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어별 빈도 계산 / 조건부 확률 계산\n",
    "\n",
    "cfd = ConditionalFreqDist(sentences)\n",
    "cpd = ConditionalProbDist(cfd, MLEProbDist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('는/Josa', 1)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 단어별 빈도 계산 함수 생성\n",
    "\n",
    "def korean_most_common(c, n, pos=None):\n",
    "    if pos is None:\n",
    "        return cfd[tokenize(c)[0]].most_common(n)\n",
    "    else:\n",
    "        return cfd[\"/\".join([c, pos])].most_common(n)\n",
    "\n",
    "korean_most_common(\"나\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 조건부 확률 계산 함수 생성\n",
    "\n",
    "def korean_bigram_prob(c, w):\n",
    "    context = tokenize(c)[0]\n",
    "    word = tokenize(w)[0]\n",
    "    return cpd[context].prob(word)\n",
    "\n",
    "korean_bigram_prob('주인공', '을')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 무작위 문장 생성 함수\n",
    "\n",
    "def generate_korean_sentence(seed = None, debug = False):\n",
    "    if seed is not None:\n",
    "        import random\n",
    "        random.seed(seed)\n",
    "    c = 'SS'\n",
    "    sentence = []\n",
    "    while True:\n",
    "        if c not in cpd:  # 문장 시작이 없으면 break\n",
    "            break\n",
    "            \n",
    "        w = cpd[c].generate()    # cpd[c]는 다음 단어 의미 (해당하는 확률값에 대한 단어)\n",
    "        \n",
    "        if w == 'SE':  # 문장이 끝이면 break\n",
    "            break\n",
    "        w2 = w.split('/')[0]\n",
    "        pos = w.split('/')[1]\n",
    "        \n",
    "        if c == 'SS':\n",
    "            sentence.append(w2.title())\n",
    "        elif c in [\"`\", \"\\\"\", \"'\", \"(\"]:\n",
    "            sentence.append(w2)\n",
    "        elif w2 in [\"'\", \".\", \",\", \")\", \":\", \";\", \"?\"]:\n",
    "            sentence.append(w2)\n",
    "        elif pos in ['Josa', 'Puncuation', 'Suffix']:\n",
    "            sentence.append(w2)\n",
    "        elif w in [\"임/Noun\", \"것/Noun\", \"는걸/Noun\", \"릴때/Noun\",\n",
    "                   \"되다/Verb\", \"이다/Verb\", \"하다/Verb\", \"이다/Adjective\"]:\n",
    "            sentence.append(w2)\n",
    "        else:\n",
    "            sentence.append(\" \" + w2) \n",
    "            \n",
    "        c = w\n",
    "        \n",
    "        if debug:\n",
    "            print(w)\n",
    "            \n",
    "    return \"\".join(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'스포일러가 포함 된 감상 평 보기'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_korean_sentence(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'막판에 참전 하는 느낌 이 때 당시 군인들 20년 뒤 히틀러라는 극악의 영화 내내 쉴 시간이 좋았다'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_korean_sentence(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 단어 표현 방법\n",
    "### : 국소 표현 방식"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - BoW (Bag of Words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이전 코드 복습\n",
    "# 문장 입력\n",
    "\n",
    "token = re.sub(\"(\\.)\", \"\", \"정부가 발표하는 물가상승률과 소비자가 느끼는 물가상승률은 다르다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['정부', '가', '발표', '하는', '물가상승률', '과', '소비자', '가', '느끼는', '물가상승률', '은', '다르다']\n"
     ]
    }
   ],
   "source": [
    "# 토큰화\n",
    "\n",
    "token = okt.morphs(token)\n",
    "print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2index = {} # 단어별 인덱스 저장\n",
    "bow = []       # 등장 횟수 vector\n",
    "\n",
    "for voca in token:\n",
    "    if voca not in word2index.keys():  \n",
    "        word2index[voca] = len(word2index)  # word2index에 없는 단어는 새로 추가\n",
    "        bow.insert(len(word2index)-1, 1)   # bow 전체에 기본값 저장, 단어 등장횟수는 최소 1 이상\n",
    "    else:\n",
    "        index = word2index.get(voca)  # 재등장 단어의 인덱스 획득\n",
    "        bow[index] = bow[index] +1    # 재등장 단어의 등장횟수 증가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'정부': 0, '가': 1, '발표': 2, '하는': 3, '물가상승률': 4, '과': 5, '소비자': 6, '느끼는': 7, '은': 8, '다르다': 9}\n"
     ]
    }
   ],
   "source": [
    "print(word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 1, 1, 2, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - BoW 전체 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = re.sub(\"(\\.)\", \"\", \"정부가 발표하는 물가상승률과 소비자가 느끼는 물가상승률은 다르다.\") \n",
    "token += re.sub(\"(\\.)\", \"\", \"소비자가 주로 소비하는 상품을 기준으로 물가상승률을 느낀다.\")\n",
    "\n",
    "token = okt.morphs(token)\n",
    "word2index = {} # 단어별 인덱스 저장\n",
    "bow = []       # 등장 횟수 vector\n",
    "\n",
    "for voca in token:\n",
    "    if voca not in word2index.keys():  \n",
    "        word2index[voca] = len(word2index)  # word2index에 없는 단어는 새로 추가\n",
    "        bow.insert(len(word2index)-1, 1)   # bow 전체에 기본값 저장, 단어 등장횟수는 최소 1 이상\n",
    "    else:\n",
    "        index = word2index.get(voca)  # 재등장 단어의 인덱스 획득\n",
    "        bow[index] = bow[index] +1    # 재등장 단어의 등장횟수 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'정부': 0, '가': 1, '발표': 2, '하는': 3, '물가상승률': 4, '과': 5, '소비자': 6, '느끼는': 7, '은': 8, '다르다': 9, '주로': 10, '소비': 11, '상품': 12, '을': 13, '기준': 14, '으로': 15, '느낀다': 16}\n"
     ]
    }
   ],
   "source": [
    "print(word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 1, 2, 3, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - CountVectorizer 클래스로 BoW 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 2 1 2 1]]\n",
      "{'you': 4, 'know': 1, 'want': 3, 'your': 5, 'love': 2, 'because': 0}\n"
     ]
    }
   ],
   "source": [
    "# CountVectorizer 클래스로 BoW 만들기: 영어\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "corpus = ['You know I want your love. because I love you']\n",
    "vector = CountVectorizer()\n",
    "\n",
    "print(vector.fit_transform(corpus).toarray()) \n",
    "print(vector.vocabulary_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0]]\n",
      "{'정부': 10, '발표': 5, '하는': 12, '물가상승률': 4, '소비자': 8, '느끼는': 1, '다르다': 3, '주로': 11, '소비': 7, '상품': 6, '기준': 0, '으로': 9, '느낀다': 2}\n"
     ]
    }
   ],
   "source": [
    "# CountVectorizer 클래스로 BoW 만들기: 한국어\n",
    "\n",
    "token = re.sub(\"(\\.)\", \"\", \"정부가 발표하는 물가상승률과 소비자가 느끼는 물가상승률은 다르다.\") \n",
    "token += re.sub(\"(\\.)\", \"\", \"소비자가 주로 소비하는 상품을 기준으로 물가상승률을 느낀다.\")\n",
    "\n",
    "token = okt.morphs(token)\n",
    "\n",
    "print(vector.fit_transform(token).toarray())\n",
    "print(vector.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⇒ 조사가 적용 안됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 1 1 1 1]]\n",
      "{'정부가': 6, '발표하는': 4, '물가상승률과': 2, '소비자가': 5, '느끼는': 0, '물가상승률은': 3, '다르다': 1}\n"
     ]
    }
   ],
   "source": [
    "# 형태소 분석 없이 BoW 만들기: 한국어\n",
    "\n",
    "token = [\"정부가 발표하는 물가상승률과 소비자가 느끼는 물가상승률은 다르다.\"]\n",
    "\n",
    "print(vector.fit_transform(token).toarray())\n",
    "print(vector.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⇒ 조사가 분리 안됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - BoW에서 불용어 제거하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 입력\n",
    "\n",
    "text = [\"Family is not an important thing. It's everything.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불용어 처리\n",
    "\n",
    "vect = CountVectorizer(stop_words = [\"the\", \"a\", \"an\", \"is\", \"not\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "print(vect.fit_transform(text).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'family': 1, 'important': 2, 'thing': 4, 'it': 3, 'everything': 0}\n"
     ]
    }
   ],
   "source": [
    "print(vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - CountVectorizer 클래스의 불용어 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(stop_words = 'english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "print(vect.fit_transform(text).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'family': 0, 'important': 1, 'thing': 2}\n"
     ]
    }
   ],
   "source": [
    "print(vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - NLTK의 불용어 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = stopwords.words('english')\n",
    "vect = CountVectorizer(stop_words = sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "print(vect.fit_transform(text).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'family': 1, 'important': 2, 'thing': 3, 'everything': 0}\n"
     ]
    }
   ],
   "source": [
    "print(vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BoW는 어떤 단어가 얼마나 등장하는지를 기준으로 문서가 어떤 성격을 가지고 있는지 판단하는 작업에 사용된다.\n",
    "\n",
    "⇒ 문서의 분류나 유사도 확인 용도"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문서 단어 행렬(Document-Term Matrix, DTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 다수의 문서에 등장하는 각 단어들의 빈도를 행렬로 표현하는 방법\n",
    "- Document가 행(row;data) / Words(Term)가 열(column;feature)\n",
    "\n",
    "\n",
    "- BoW는 하나의 문서에 대한 단어 빈도 확인\n",
    "- DTM은 다수의 문서에 대한 단어 빈도 확인 (BoW의 matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "한계)\n",
    "    1. 희소 행령 또는 희소 벡터 문제: 대부분의 값이 0, 많은 양의 저장 공간 필요\n",
    "    -> vector 크기를 줄이는 방법 (전처리 단계에서 의미 없는 불용어 처리 필요)\n",
    "    \n",
    "    2. 단순 빈도 수 기반 접근이므로, 문서 유사도 판별 시 정확한 판별이 어려움\n",
    "    -> 가중치를 적용하는 방법 (한 문서에서의 빈도, 여러 문서에서의 빈도 비교)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF(Term Frequency-Inverse Document Frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 단어 빈도 - 역 문서 빈도\n",
    "- 단어의 빈도와 역 문서 빈도(문서의 빈도에 특정식을 취한 것)를 사용하여 DTM 내의 각 단어들마다 중요한 정도를 가중치로 주는 방법\n",
    "\n",
    "- 먼저 DTM을 작성한 후, TF-IDF 가중치를 부여\n",
    "    \n",
    "⇒ 문서 간 유사성을 파악하거나 검색 시스템에서 검색 결과의 중요도, 문서 내에서 특정 단어의 중요도를 구하는 작업"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. tf(d,t): 특정 문서 d에서의 특정 단어 t의 등장 횟수, DTM에서 각 단어들이 가진 값     \n",
    "ex) 문서1 ('먹고 싶은 바나나') : tf(문서1, 바나나) = 1\n",
    "        \n",
    "#### 2. df(t): 특정 단어 t가 등장한 문서의 수\n",
    "ex) 문서1, 문서2에 '바나나' 등장 : df = 2\n",
    "    \n",
    "#### 3. idf(d,t): df(t)에 반비례하는 수\n",
    "    idf(d,t) = log(n / 1 + df(t))\n",
    "\n",
    "- 분모가 0 되는 것을 방지하기 위해, 1을 더함\n",
    "- log: 수가 지나치게 커지는 것 방지\n",
    "         \n",
    "⇒ 여러 문서에 등장한 단어의 가중치가 낮아짐\n",
    "     \n",
    "#### 4. TF-IDF: tf(d,t) * idf(d,t)\n",
    "         \n",
    "⇒ 한 문서에 같은 단어가 여러 번 나온다면 가중치가 높아짐\n",
    "\n",
    "\n",
    "- TF-IDF 값이 클수록 중요도가 큰 것\n",
    "- the, a와 같은 불용어의 경우, 모든 문서에 자주 등장하기 때문에 TF-IDF값이 낮아지게 됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Scikit-learn을 이용한 DTM과 TF-IDF 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 1 0 1 0 1 1]\n",
      " [0 0 1 0 0 0 0 1 0]\n",
      " [1 0 0 0 1 0 1 0 0]]\n",
      "{'you': 7, 'know': 1, 'want': 5, 'your': 8, 'love': 3, 'like': 2, 'what': 6, 'shoud': 4, 'do': 0}\n"
     ]
    }
   ],
   "source": [
    "# DTM 만들기\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "corpus = [\n",
    "    'you know I want your love',\n",
    "    'I like you',\n",
    "    'what shoud I do',\n",
    "]\n",
    "vector = CountVectorizer()\n",
    "\n",
    "# 3개의 문서, 각 문서에 대한 단어 빈도수 계산\n",
    "print(vector.fit_transform(corpus).toarray())\n",
    "print(vector.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⇒ 단순히 한 단어가 두 문서에 다 나타났다고 해서 유사성이 높다고 볼 수는 없다.\n",
    "   \n",
    "    여러 문서 내 단어의 중요도를 계산할 수 있는 보다 정교한 방법 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.46735098 0.         0.46735098 0.         0.46735098\n",
      "  0.         0.35543247 0.46735098]\n",
      " [0.         0.         0.79596054 0.         0.         0.\n",
      "  0.         0.60534851 0.        ]\n",
      " [0.57735027 0.         0.         0.         0.57735027 0.\n",
      "  0.57735027 0.         0.        ]]\n",
      "{'you': 7, 'know': 1, 'want': 5, 'your': 8, 'love': 3, 'like': 2, 'what': 6, 'shoud': 4, 'do': 0}\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF 계산\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "corpus = [\n",
    "    'you know I want your love',\n",
    "    'I like you',\n",
    "    'what shoud I do',\n",
    "]\n",
    "tfidfv = TfidfVectorizer().fit(corpus)\n",
    "\n",
    "print(tfidfv.transform(corpus).toarray())\n",
    "print(tfidfv.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 문서 유사도\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 코사인 유사도 (Cosine Similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"https://s0.wp.com/latex.php?latex=%5Ctext%7Bsimilarity%7D+%3D+cos%28%5Ctheta%29+%3D+%7BA+%5Ccdot+B+%5Cover+%7CA%7C+%7CB%7C%7D+%3D+%5Cfrac%7B+%5Csum%5Climits_%7Bi%3D1%7D%5E%7Bn%7D%7BA_i+%5Ctimes+B_i%7D+%7D%7B+%5Csqrt%7B%5Csum%5Climits_%7Bi%3D1%7D%5E%7Bn%7D%7B%28A_i%29%5E2%7D%7D+%5Ctimes+%5Csqrt%7B%5Csum%5Climits_%7Bi%3D1%7D%5E%7Bn%7D%7B%28B_i%29%5E2%7D%7D+%7D&bg=T&fg=000000&s=0\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"https://wikidocs.net/images/page/24603/%EC%BD%94%EC%82%AC%EC%9D%B8%EC%9C%A0%EC%82%AC%EB%8F%84.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BoW, DTM, TF-IDF, 또는 Word2Vec 등과 같이 단어를 수치화할 수 있는 방법에서 코사인 유사도를 이용하여 문서의 유사도를 구함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코사인 유사도 계산 함수\n",
    "\n",
    "def cos_sim(A, B):\n",
    "    return dot(A, B) / (norm(A) * norm(B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = np.array([0,1,1,1])\n",
    "doc2 = np.array([1,0,1,1])\n",
    "doc3 = np.array([2,0,2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666667\n",
      "0.6666666666666667\n",
      "1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "print(cos_sim(doc1, doc2))\n",
    "print(cos_sim(doc1, doc3))\n",
    "print(cos_sim(doc2, doc3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 문서 1과 2 / 문서 1과 3의 유사도 값이 같으므로, 문서 2와 3의 유사도 값은 1\n",
    "- 벡터의 방향이 완전히 동일하면 코사인 유사도: 1\n",
    "    - -1: 서로 완전히 반대되는 경우\n",
    "    - 0 : 서로 독립적인 경우\n",
    "    - 1 : 서로 완전히 같은 경우\n",
    "    \n",
    "- 한 문서 내의 모든 단어의 빈도수가 똑같이 증가하는 경우에는 기존의 문서와 코사인 유사도 값은 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    문서1 : 저는 사과 좋아요\n",
    "    문서2 : 저는 바나나 좋아요\n",
    "    문서3 : 저는 바나나 좋아요 저는 바나나 좋아요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 유클리드 거리 (Euclidean distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"https://t1.daumcdn.net/cfile/tistory/99829F425E17C5801E\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"https://t1.daumcdn.net/cfile/tistory/99AD47485E17C4D11C\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다차원 공간에서 두 개의 점이 각각 좌표를 가질 때, 두 점 사이의 거리(d(x,y))를 계산\n",
    "\n",
    "    d^2 = x^2 + y^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유클리드 거리 계산 함수\n",
    "\n",
    "def dist(x,y):\n",
    "    return np.sqrt(np.sum((x-y)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = np.array((2,3,0,1))\n",
    "doc2 = np.array((1,2,3,1))\n",
    "doc3 = np.array((2,1,2,2))\n",
    "docQ = np.array((1,1,0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.23606797749979\n",
      "3.1622776601683795\n",
      "2.449489742783178\n"
     ]
    }
   ],
   "source": [
    "print(dist(doc1, docQ))\n",
    "print(dist(doc2, docQ))\n",
    "print(dist(doc3, docQ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 유클리드 거리의 값은 작을수록, 거리가 가까운 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 자카드 유사도 (Jaccard similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"data:image/png;base64,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\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "합집합에서 교집합의 비율을 구함\n",
    "  - 0 : 서로 독립적인 경우\n",
    "  - 1 : 서로 완전히 같은 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = \"apple banana everyone like likey watch card holder\"\n",
    "doc2 = \"apple banana coupon passport love you\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰화\n",
    "\n",
    "tokenized_doc1 = doc1.split()\n",
    "tokenized_doc2 = doc2.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apple', 'banana', 'everyone', 'like', 'likey', 'watch', 'card', 'holder']\n",
      "['apple', 'banana', 'coupon', 'passport', 'love', 'you']\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_doc1)\n",
    "print(tokenized_doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'banana', 'passport', 'likey', 'love', 'apple', 'like', 'watch', 'you', 'holder', 'card', 'everyone', 'coupon'}\n"
     ]
    }
   ],
   "source": [
    "# 합집합 계산\n",
    "\n",
    "union = set(tokenized_doc1).union(set(tokenized_doc2)) # set: 중복 허용 않고, 순서 상관 없이 데이터 저장\n",
    "print(union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'banana', 'apple'}\n"
     ]
    }
   ],
   "source": [
    "# 교집합 계산\n",
    "\n",
    "intersection = set(tokenized_doc1).intersection(set(tokenized_doc2))\n",
    "print(intersection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16666666666666666\n"
     ]
    }
   ],
   "source": [
    "# 자카드 유사도 계산\n",
    "\n",
    "print(len(intersection)/len(union))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
